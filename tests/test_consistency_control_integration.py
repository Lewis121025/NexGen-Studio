"""æµ‹è¯•ä¸€è‡´æ€§æ§åˆ¶åŠŸèƒ½ã€‚"""

from __future__ import annotations

import pytest
from unittest.mock import AsyncMock, MagicMock, patch

from lewis_ai_system.creative.consistency_manager import ConsistencyManager
from lewis_ai_system.creative.models import CreativeProject, StoryboardPanel


class TestConsistencyManager:
    """æµ‹è¯•ä¸€è‡´æ€§ç®¡ç†å™¨ã€‚"""

    @pytest.fixture
    def consistency_manager(self):
        """åˆ›å»ºä¸€è‡´æ€§ç®¡ç†å™¨å®ä¾‹ã€‚"""
        manager = ConsistencyManager()
        # Mock LLM provider
        manager._llm_provider = AsyncMock()
        return manager

    @pytest.fixture
    def sample_project(self):
        """åˆ›å»ºç¤ºä¾‹é¡¹ç›®ã€‚"""
        return CreativeProject(
            id="test_project",
            tenant_id="test_tenant",
            title="Test Project",
            brief="Test brief for consistency control",
            consistency_level="medium",
            character_reference="A young professional",
            scene_reference="Modern office setting"
        )

    @pytest.fixture
    def sample_panel(self):
        """åˆ›å»ºç¤ºä¾‹åˆ†é•œé¢æ¿ã€‚"""
        return StoryboardPanel(
            scene_number=1,
            description="A person working at a desk",
            duration_seconds=5,
            visual_reference_path="https://example.com/image1.jpg"
        )

    @pytest.mark.asyncio
    async def test_extract_consistency_features_success(self, consistency_manager):
        """æµ‹è¯•ç‰¹å¾æå–æˆåŠŸæƒ…å†µã€‚"""
        # Mock LLM response with direct JSON that can be parsed
        mock_response = {
            "content": '''{"character_features": {"gender": "male", "age_range": "adult", "hair_style": "short hair", "clothing_style": "business casual"}, "scene_features": {"environment": "office", "lighting": "natural light", "color_scheme": "neutral tones"}, "style_features": {"art_style": "realistic", "visual_mood": "professional"}}'''
        }
        consistency_manager._llm_provider.analyze_image = AsyncMock(return_value=mock_response)

        features = await consistency_manager.extract_consistency_features("https://example.com/test.jpg")

        assert "character_features" in features
        assert "scene_features" in features
        assert "style_features" in features
        assert features["character_features"]["gender"] == "male"

    @pytest.mark.asyncio
    async def test_extract_consistency_features_fallback(self, consistency_manager):
        """æµ‹è¯•ç‰¹å¾æå–å¤±è´¥æ—¶çš„å›é€€æœºåˆ¶ã€‚"""
        consistency_manager._llm_provider.analyze_image = AsyncMock(side_effect=Exception("API Error"))

        features = await consistency_manager.extract_consistency_features("https://example.com/test.jpg")

        # åº”è¯¥è¿”å›é»˜è®¤ç‰¹å¾
        assert "character_features" in features
        assert features["character_features"]["gender"] == "æœªæŒ‡å®š"

    @pytest.mark.asyncio
    async def test_generate_consistency_prompt(self, consistency_manager):
        """æµ‹è¯•ä¸€è‡´æ€§æç¤ºè¯ç”Ÿæˆã€‚"""
        base_prompt = "A person walking in the park"
        features = {
            "character_features": {"gender": "female", "age_range": "young adult"},
            "scene_features": {"environment": "park", "lighting": "sunny"},
            "style_features": {"art_style": "realistic"}
        }

        prompt = await consistency_manager.generate_consistency_prompt(
            base_prompt, features, "medium"
        )

        assert base_prompt in prompt
        assert "è§’è‰²ç‰¹å¾" in prompt or "character" in prompt.lower()

    @pytest.mark.asyncio
    async def test_evaluate_consistency_perfect_score(self, consistency_manager):
        """æµ‹è¯•ä¸€è‡´æ€§è¯„ä¼° - å®Œç¾åˆ†æ•°ã€‚"""
        images = ["https://example.com/image1.jpg"]  # å•ä¸ªå›¾ç‰‡

        result = await consistency_manager.evaluate_consistency(images)

        assert result["overall_score"] == 1.0
        assert result["passed"] is True

    @pytest.mark.asyncio
    async def test_evaluate_consistency_with_multiple_images(self, consistency_manager):
        """æµ‹è¯•ä¸€è‡´æ€§è¯„ä¼° - å¤šä¸ªå›¾ç‰‡ã€‚"""
        images = ["https://example.com/image1.jpg", "https://example.com/image2.jpg"]

        # Mock LLM response
        mock_response = {
            "content": "Overall consistency score: 0.85"
        }
        consistency_manager._llm_provider.complete = AsyncMock(return_value=mock_response["content"])

        result = await consistency_manager.evaluate_consistency(images)

        assert "overall_score" in result
        assert "character_consistency" in result
        assert "scene_consistency" in result
        assert "style_consistency" in result
        assert isinstance(result["passed"], bool)

    def test_generate_consistency_seed(self, consistency_manager, sample_project):
        """æµ‹è¯•ä¸€è‡´æ€§ç§å­ç”Ÿæˆã€‚"""
        seed1 = consistency_manager.generate_consistency_seed(sample_project.id, 1)
        seed2 = consistency_manager.generate_consistency_seed(sample_project.id, 1)

        # ç›¸åŒè¾“å…¥åº”è¯¥ç”Ÿæˆç›¸åŒç§å­
        assert seed1 == seed2
        assert isinstance(seed1, int)
        assert 0 <= seed1 < 2**31

    def test_weighted_consistency_score(self, consistency_manager):
        """æµ‹è¯•åŠ æƒä¸€è‡´æ€§è¯„åˆ†ã€‚"""
        scores = {
            "character_consistency": 0.8,
            "scene_consistency": 0.9,
            "style_consistency": 0.7,
            "visual_similarity": 0.6
        }

        weighted_score = consistency_manager._weighted_consistency_score(scores)

        assert 0 <= weighted_score <= 1
        # ç”±äºè§’è‰²ä¸€è‡´æ€§æƒé‡æœ€é«˜ï¼ˆ0.4ï¼‰ï¼Œåˆ†æ•°åº”è¯¥æ¥è¿‘0.8
        assert 0.75 <= weighted_score <= 0.85

    def test_generate_consistency_recommendations(self, consistency_manager):
        """æµ‹è¯•ä¸€è‡´æ€§å»ºè®®ç”Ÿæˆã€‚"""
        scores = {
            "character_consistency": 0.5,  # ä½åˆ†
            "scene_consistency": 0.9,      # é«˜åˆ†
            "style_consistency": 0.6,      # ä¸­ç­‰
            "visual_similarity": 0.8       # é«˜åˆ†
        }

        recommendations = consistency_manager._generate_consistency_recommendations(scores, 0.7)

        assert isinstance(recommendations, list)
        assert len(recommendations) > 0
        # åº”è¯¥åŒ…å«è§’è‰²ä¸€è‡´æ€§çš„å»ºè®®
        role_recommendations = [r for r in recommendations if "è§’è‰²" in r or "character" in r.lower()]
        assert len(role_recommendations) > 0


class TestBatchProcessingService:
    """æµ‹è¯•æ‰¹é‡å¤„ç†æœåŠ¡ã€‚"""

    @pytest.fixture
    def batch_service(self):
        """åˆ›å»ºæ‰¹é‡å¤„ç†æœåŠ¡å®ä¾‹ã€‚"""
        from lewis_ai_system.creative.batch_processing import BatchProcessingService
        return BatchProcessingService()

    @pytest.mark.asyncio
    async def test_batch_evaluate_consistency(self, batch_service):
        """æµ‹è¯•æ‰¹é‡ä¸€è‡´æ€§è¯„ä¼°ã€‚"""
        project_ids = ["project1", "project2", "project3"]

        # Mock repository
        with patch('lewis_ai_system.creative.batch_processing.creative_repository') as mock_repo, \
             patch('lewis_ai_system.creative.batch_processing.consistency_manager') as mock_manager:

            # Mock projects
            mock_projects = []
            for i, pid in enumerate(project_ids):
                project = MagicMock()
                project.id = pid
                project.storyboard = []
                if i < 2:  # å‰ä¸¤ä¸ªé¡¹ç›®æœ‰åˆ†é•œ
                    panel = MagicMock()
                    panel.visual_reference_path = f"https://example.com/image{i+1}.jpg"
                    project.storyboard = [panel]
                mock_projects.append(project)

            mock_repo.get = AsyncMock(side_effect=mock_projects)

            # Mock consistency evaluation
            mock_result = {
                "overall_score": 0.8,
                "character_consistency": 0.8,
                "scene_consistency": 0.7,
                "style_consistency": 0.9,
                "recommendations": ["Test recommendation"]
            }
            mock_manager.evaluate_consistency = AsyncMock(return_value=mock_result)
            mock_repo.upsert = AsyncMock()

            result = await batch_service.batch_evaluate_consistency(project_ids)

            assert result["total_projects"] == 3
            # æ‰¹é‡ä¸€è‡´æ€§è¯„ä¼°éœ€è¦è‡³å°‘2å¼ åˆ†é•œå›¾ç‰‡ï¼Œæ‰€æœ‰é¡¹ç›®éƒ½åªæœ‰1å¼ æˆ–æ²¡æœ‰ï¼Œæ‰€ä»¥éƒ½è¢«è·³è¿‡
            assert result["successful_evaluations"] == 0
            assert result["total_processed"] == 3  # å…¨éƒ¨é¡¹ç›®éƒ½è¢«å¤„ç†äº†
            assert "project1" in result["results"]
            assert "project2" in result["results"]
            assert "project3" in result["results"]

            # æ£€æŸ¥æ‰€æœ‰é¡¹ç›®çš„çŠ¶æ€éƒ½æ˜¯è·³è¿‡ï¼ˆåˆ†é•œä¸è¶³ï¼‰
            for project_id in ["project1", "project2", "project3"]:
                project_result = result["results"][project_id]
                assert project_result["status"] == "skipped"


class TestMonitoringAnalyticsService:
    """æµ‹è¯•ç›‘æ§å’Œåˆ†ææœåŠ¡ã€‚"""

    @pytest.fixture
    def monitoring_service(self):
        """åˆ›å»ºç›‘æ§æœåŠ¡å®ä¾‹ã€‚"""
        from lewis_ai_system.creative.monitoring import MonitoringAnalyticsService
        return MonitoringAnalyticsService()

    @pytest.mark.asyncio
    async def test_get_consistency_stats(self, monitoring_service):
        """æµ‹è¯•ä¸€è‡´æ€§ç»Ÿè®¡è·å–ã€‚"""
        with patch('lewis_ai_system.creative.monitoring.creative_repository') as mock_repo:
            # Mock projects
            mock_projects = []
            for i in range(5):
                project = MagicMock()
                project.consistency_level = "medium" if i < 3 else "high"
                project.overall_consistency_score = 0.7 + i * 0.05 if i < 4 else None
                project.storyboard = []
                mock_projects.append(project)

            mock_repo.list_for_tenant = AsyncMock(return_value=mock_projects)

            stats = await monitoring_service.get_consistency_stats("test_tenant")

            assert stats["total_projects"] == 5
            assert stats["projects_with_consistency_score"] == 4
            assert "average_consistency_score" in stats
            assert "consistency_level_distribution" in stats
            assert "score_ranges" in stats

    @pytest.mark.asyncio
    async def test_get_consistency_trends(self, monitoring_service):
        """æµ‹è¯•ä¸€è‡´æ€§è¶‹åŠ¿è·å–ã€‚"""
        with patch('lewis_ai_system.creative.monitoring.creative_repository') as mock_repo:
            # Mock projects with different dates
            from datetime import datetime, timezone, timedelta

            mock_projects = []
            base_date = datetime.now(timezone.utc)

            for i in range(7):
                project = MagicMock()
                project.created_at = base_date - timedelta(days=i)
                project.updated_at = project.created_at + timedelta(hours=1)
                project.overall_consistency_score = 0.7 + (i % 3) * 0.1
                project.storyboard = []
                mock_projects.append(project)

            mock_repo.list_for_tenant = AsyncMock(return_value=mock_projects)

            trends = await monitoring_service.get_consistency_trends("test_tenant", days=7)

            assert "trends" in trends
            assert "summary" in trends
            assert len(trends["trends"]) > 0

            # æ£€æŸ¥è¶‹åŠ¿æ‘˜è¦
            summary = trends["summary"]
            assert "trend" in summary
            assert "improvement" in summary

    @pytest.mark.asyncio
    async def test_get_recommendations(self, monitoring_service):
        """æµ‹è¯•æ™ºèƒ½æ¨èç”Ÿæˆã€‚"""
        with patch('lewis_ai_system.creative.monitoring.creative_repository') as mock_repo:
            # Mock projects with low consistency scores
            mock_projects = []
            for i in range(3):
                project = MagicMock()
                project.consistency_level = "low"
                project.overall_consistency_score = 0.5  # ä½åˆ†
                project.state = "completed"
                project.cost_usd = 10.0
                project.storyboard = []
                mock_projects.append(project)

            mock_repo.list_for_tenant = AsyncMock(return_value=mock_projects)

            recommendations = await monitoring_service.get_recommendations("test_tenant")

            assert "recommendations" in recommendations
            assert isinstance(recommendations["recommendations"], list)

            # åº”è¯¥æœ‰æå‡ä¸€è‡´æ€§çš„æ¨è
            consistency_recs = [r for r in recommendations["recommendations"]
                              if r.get("type") == "consistency_improvement"]
            assert len(consistency_recs) > 0


class TestIntegration:
    """é›†æˆæµ‹è¯•ã€‚"""

    @pytest.mark.asyncio
    async def test_full_consistency_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„ä¸€è‡´æ€§å·¥ä½œæµã€‚"""
        # åˆ›å»ºé¡¹ç›®
        project = CreativeProject(
            id="integration_test",
            tenant_id="test",
            title="Integration Test",
            brief="Test full consistency workflow",
            consistency_level="high"
        )

        # åˆå§‹åŒ–ä¸€è‡´æ€§ç®¡ç†å™¨
        manager = ConsistencyManager()
        manager._llm_provider = AsyncMock()

        # Mock ç‰¹å¾æå–
        features = {
            "character_features": {"gender": "female", "age_range": "adult"},
            "scene_features": {"environment": "office"},
            "style_features": {"art_style": "realistic"}
        }
        manager.extract_consistency_features = AsyncMock(return_value=features)

        # æµ‹è¯•ç‰¹å¾æå–
        extracted = await manager.extract_consistency_features("test_url")
        assert extracted == features

        # æµ‹è¯•æç¤ºè¯ç”Ÿæˆ
        prompt = await manager.generate_consistency_prompt(
            "A person working", features, "high"
        )
        assert isinstance(prompt, str)
        assert len(prompt) > 0

        # æµ‹è¯•ç§å­ç”Ÿæˆ
        seed = manager.generate_consistency_seed(project.id)
        assert isinstance(seed, int)

        # æµ‹è¯•ä¸€è‡´æ€§è¯„ä¼°ï¼ˆå•ä¸ªå›¾ç‰‡ï¼‰
        result = await manager.evaluate_consistency(["test_image.jpg"])
        assert result["overall_score"] == 1.0  # å•ä¸ªå›¾ç‰‡è¿”å›1.0

        print("[OK] å®Œæ•´ä¸€è‡´æ€§å·¥ä½œæµé›†æˆæµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    # è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
    import asyncio

    async def run_basic_tests():
        print("å¼€å§‹ä¸€è‡´æ€§æ§åˆ¶åŸºç¡€åŠŸèƒ½æµ‹è¯•...")

        manager = ConsistencyManager()
        manager._llm_provider = AsyncMock()

        # æµ‹è¯•ç§å­ç”Ÿæˆ
        seed = manager.generate_consistency_seed("test_project")
        print(f"[OK] ç§å­ç”Ÿæˆæµ‹è¯•é€šè¿‡: {seed}")

        # æµ‹è¯•åŠ æƒè¯„åˆ†
        scores = {"character_consistency": 0.8, "scene_consistency": 0.9}
        weighted = manager._weighted_consistency_score(scores)
        print(f"[OK] åŠ æƒè¯„åˆ†æµ‹è¯•é€šè¿‡: {weighted}")

        # æµ‹è¯•å»ºè®®ç”Ÿæˆ
        recommendations = manager._generate_consistency_recommendations(scores, 0.7)
        print(f"[OK] å»ºè®®ç”Ÿæˆæµ‹è¯•é€šè¿‡: {len(recommendations)} æ¡å»ºè®®")

        print("ğŸ‰ æ‰€æœ‰åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")

    asyncio.run(run_basic_tests())
